---
layout: 	landing-page
year:		2020
title: 		'@CVPR 2020, Seattle, WA'
date: 		'Sunday June 14th'
location: 	'Location: Virtual'
banner:		/images/2020/banner.jpg

redirect_from: "/"
---
<!-- Main -->
<article id="main">
    
<!-- One -->
    <section class="wrapper style3 container">

        <!-- Content -->
        <div class="content">
            <section>
                <header>
                    <h2>The 2nd International Workshop on Dynamic Scene Reconstruction</h2>
                </header>
                <p>
                    Reconstruction of general dynamic scenes is motivated by potential applications in film and broadcast production together with the ultimate goal of automatic understanding of real-world scenes from distributed camera networks. With recent advances in hardware and the advent of virtual and augmented reality, dynamic scene reconstruction is being applied to more complex scenes with applications in Entertainment, Games, Film, Creative Industries and AR/VR/MR. We welcome contributions to this workshop in the form of oral presentations and posters. Suggested topics include, but are not limited to:
                </p>
                <ul>
                    <li>- Dynamic 3D reconstruction from single, stereo or multiple views</li>
                    <li>- Learning-based methods in dynamic scene reconstruction and understanding</li>
                    <li>- Multi-modal dynamic scene modelling (RGBD, LIDAR, 360 video, light fields)</li>
                    <li>- 4D reconstruction and modelling</li>
                    <li>- 3D/4D data acquisition, representation, compression and transmission</li>
                    <li>- Scene analysis and understanding in 2D and 3D</li>
                    <li>- Structure from motion, camera calibration and pose estimation</li>
                    <li>- Digital humans: motion and performance capture, bodies, faces, hands</li>
                    <li>- Geometry processing</li>
                    <li>- Computational photography</li>
                    <li>- Appearance and reflectance modelling</li>
                    <li>- Scene modelling in the wild, moving cameras, handheld cameras</li>
                    <li>- Applications of dynamic scene reconstruction (VR/AR, character animation, free-viewpoint video, relighting, medical imaging, creative content production, animal tracking, HCI, sports)</li>
                </ul>
               
                <p><strong>The objectives for this workshop are to:</strong></p>
                <ul>
                    <li>- Bringing together leading experts in the field of general dynamic scene reconstruction to help propel the field forward.</li>
                    <li>- Create and maintain an online database of datasets and papers</li>
                    <li>- Accelerate research progress in the field of dynamic scene reconstruction to match the requirements of real-world applications by identifying the challenges and ways to address them through a panel discussion between experts, presenters and attendees.</li>
                </ul>

            </section>
        </div>
    </section>
    
    
    
    <!-- Three -->
    <section class="wrapper style3 container special" id="speakers">
    
        <header class="major">
            <h2><strong>Speakers</strong></h2>
        </header>
        <div class="row">
            <div class="3u">
                <a href="http://www.cs.cmu.edu/~yaser/" target="_blank">
                    <section>
                        <img class="image-circle" src="/images/2020/ys.png" alt=""/>
                        <header>
                            <h3><strong>Yaser <br> Sheik</strong></h3>
                        </header>
                        <p> Director, Oculus Research Pittsburgh, and Carnegie Mellon University</p>
                    </section>
                </a>

            </div>
            <div class="3u">
                <a href="http://www.cs.toronto.edu/~urtasun/" target="_blank">
                    <section>
                        <img class="image-circle" src="/images/2020/ru.jpg" alt=""/>
                        <header>
                            <h3><strong>Raquel<br> Urtasun</strong></h3>
                        </header>
                        <p>Uber ATG Chief Scientist and the Head of Uber ATG Toronto, University of Toronto</p>
                    </section>
                </a>
            </div>
    </section>
    
    
    <!-- Three -->
    <section class="wrapper style3 container special" id="program">
    
        <header class="major">
            <h2><strong>Program</strong></h2>
        </header>
        <h3><strong>14th June, Morning Session</strong></h3>
        
       <div class="row">
           <table >
	            <colgroup>
			       <col span="1" style="width: 25%;">
			       <col span="1" style="width: 75%;">
			  	</colgroup>
                    <tbody >
                            <tr>
                                <td><strong>Time (PST)</strong></td>
                                <td><strong>Session</strong></td>
                            </tr>
                            <tr>
                                <td><span >08:30 - 08:40</span></td>
                                <td><span ><b>Welcome and Introduction</b></span></td>
                            </tr>
                            <tr>
                                <td><span >08:40 - 09:25</span></td>
                                <td><span ><b>Keynote 1: Yaser Sheikh</b><br>
											Topic TBA</span>
								</td>
                            </tr>
                            <tr>
                                <td><span >09:25 - 09:35</span></td>
                                <td><span ><b>Break</b></span></td>
                            </tr>
                            <tr>
                                <td><span >09:35 - 10:35</span></td>
                                <td>
                                	<span ><b>Paper Session (15 mins each)</b></span>

<p><b>Semi-supervised 3D Face Representation Learning from Unconstrained Photo Collections</b><br>
Zhongpai Gao, Juyong Zhang, Yudong Guo, Chao Ma, Guangtao Zhai, Xiaokang Yang</p>

<p><b>Bilinear Parameterization For Differentiable Rank-Regularization</b><br>
Marcus Valtonen Örnhag, Carl Olsson, Anders Heyden</p>

<p><b>The “Vertigo Effect” on Your Smartphone: Dolly Zoom via Single Shot View Synthesis</b><br>
Yangwen Liang, Rohit Ranade, Shuangquan Wang, Dongwoon Bai, Jungwon Lee</p>

<p><b>RGBD-Dog: Predicting Canine Pose from RGBD Sensors (Invited CVPR poster)</b><br>
Sinead Kearney, Wenbin Li, Martin Parsons, Kwang In Kim, Darren Cosker</p>
                                
                                </td>            
                            </tr>
                            <tr>
                                <td><span >10:35 - 10:50</span></td>
                                <td><span ><b>Break</b></span></td>
                            </tr>
                            <tr>
                                <td><span >10:50 - 11:35</span></td>
                                <td><span ><b>Keynote 2: Raquel Urtasun</b><br>
Topic TBA
                                </span></td>
                            </tr>
                            <tr>
                                <td><span >11:35 - 12.05</span></td>
                                <td><span ><b>Panel Discussion</b></span></td>
                            </tr>
                            <tr>
                                <td><span >12:05 - 12:15</span></td>
                                <td><span ><b>Close and Best Paper</b></span></td>
                            </tr>
				</tbody>
			</table>
        </div>
        
       
       <br/>
       <hr/> 
       <h3><strong>14th June, Evening Session<sup>*</sup></strong></h3>
        
       <div class="row">
           <table >
	            <colgroup>
			       <col span="1" style="width: 25%;">
			       <col span="1" style="width: 75%;">
			  	</colgroup>
                    <tbody >
                            <tr>
                                <td><strong>Time (PST)</strong></td>
                                <td><strong>Session</strong></td>
                            </tr>
                            <tr>
                                <td><span >20:30 - 20:40</span></td>
                                <td><span ><b>Welcome and Introduction</b></span></td>
                            </tr>
                            <tr>
                                <td><span >20:40 - 21:25</span></td>
                                <td><span ><b>Keynote 1: Yaser Sheikh</b><br>
											Topic TBA</span>
								</td>
                            </tr>
                            <tr>
                                <td><span >21:25 - 21:35</span></td>
                                <td><span ><b>Break</b></span></td>
                            </tr>
                            <tr>
                                <td><span >21:35 - 22:35</span></td>
                                <td>
                                	<span ><b>Paper Session (15 mins each)</b></span>

<p><b>Semi-supervised 3D Face Representation Learning from Unconstrained Photo Collections</b><br>
Zhongpai Gao, Juyong Zhang, Yudong Guo, Chao Ma, Guangtao Zhai, Xiaokang Yang</p>

<p><b>Bilinear Parameterization For Differentiable Rank-Regularization</b><br>
Marcus Valtonen Örnhag, Carl Olsson, Anders Heyden</p>

<p><b>The “Vertigo Effect” on Your Smartphone: Dolly Zoom via Single Shot View Synthesis</b><br>
Yangwen Liang, Rohit Ranade, Shuangquan Wang, Dongwoon Bai, Jungwon Lee</p>

<p><b>RGBD-Dog: Predicting Canine Pose from RGBD Sensors (Invited CVPR poster)</b><br>
Sinead Kearney, Wenbin Li, Martin Parsons, Kwang In Kim, Darren Cosker</p>
                                
                                </td>            
                            </tr>
                            <tr>
                                <td><span >22:35 - 22:50</span></td>
                                <td><span ><b>Break</b></span></td>
                            </tr>
                            <tr>
                                <td><span >22:50 - 23:35</span></td>
                                <td><span ><b>Keynote 2: Raquel Urtasun</b><br>
Topic TBA
                                </span></td>
                            </tr>
                            <tr>
                                <td><span >23:35 - 00.05</span></td>
                                <td><span >
<b>Live Q&A discussion with authors and speakers</b></span></td>
                            </tr>
                            <tr>
                                <td><span >00:05 - 00:15</span></td>
                                <td><span ><b>Close and Best Paper</b></span></td>
                            </tr>
                            <tr>
                                <td><span >00:15 - 00:45</span></td>
                                <td><span ><b>Recording of Panel Discussion (from 11:35)</b></span></td>
                            </tr>        
                        
				</tbody>
			</table>
			<p><sup>*</sup> Sessions maybe pre-recorded</p>
        </div>
        
        
   </section>
    
        <section class="wrapper style3 container special" id="submission">
    
        <header class="major">
            <h2><strong>Submission</strong></h2>
       </header>
         
        <p>We welcome submissions from both industry and academia, including interdisciplinary work and work from those outside of the mainstream computer vision community.</p>
                 
        <div class="row">
  
              <div class="6u">
            
                <section>
                    <header>
                        <h3>Instructions</h3>
                    </header>
                    <p>Papers will be limited up to 8 pages according to the <a href="http://cvpr2020.thecvf.com/submission/main-conference/author-guidelines" target="_blank">CVPR format</a> (main conference authors guidelines). All papers will be reviewed with double blind policy. Papers will be selected based on relevance, significance and novelty of results, technical merit, and clarity of presentation.</p>
                    <p><a href="https://cmt3.research.microsoft.com/DYNAVIS2020" target="_blank">Submission website</a> </p> 
                </section>
            
            </div>
            <div class="6u">
            
                <section>
                    <header>
                        <h3>Important Dates</h3>
                    </header>
                        <table >
                            <tbody >
                                <tr>
                                    <td><strong>Action</strong></td>
                                    <td><strong>Date</strong></td>
                                </tr>
                                <tr>
                                    <td><span >Paper submission deadline</span></td>
                                    <td><span >March 16, 2020</span></td>
                                </tr>
                                <tr>
                                    <td><span >Notification to authors</span></td>
                                    <td><span >March 30, 2020</span></td>
                                </tr>
                                <tr>
                                    <td><span >Camera ready deadline</span></td>
                                    <td><span >April 16, 2020</span></td>
                                </tr>
                            </tbody>
                        </table>

                </section>            
            </div>
            
  
			<div class="12u">
				<header>
					<h3>Prize</h3>
				</header>
				<p>The best paper will receive a <b>NVIDIA TITAN RTX GPU</b>, courtesy of our workshop sponsor <a href="https://www.nvidia.com/" target="_blank">NVIDIA</a>.</p>
			</div>
        </div>
    </section> 
     
    <!-- Three -->
    <section class="wrapper style3 container special" id="organizers">
    
        <header class="major">
            <h2><strong>Organizers</strong></h2>
        </header>
        <div class="row">
            <div class="3u">
                <a href="https://arminmustafa.github.io/" target="_blank">
                    <section>
                        <img class="image-circle" src="/images/organisers/am.jpg" alt=""/>
                        <header>
                            <h3><strong>Armin<br> Mustafa</strong></h3>
                        </header>
                        <p>Centre for Vision, Speech and Signal Processing, University of Surrey, UK</p>
                    </section>
                </a>

            </div>
            <div class="3u">
                <a href="https://marcovolino.github.io/" target="_blank">
                    <section>
                        <img class="image-circle" src="/images/organisers/mv.png" alt=""/>
                        <header>
                            <h3><strong>Marco<br> Volino</strong></h3>
                        </header>
                        <p>Centre for Vision, Speech and Signal Processing, University of Surrey, UK</p>
                    </section>
                </a>
            </div>
            <div class="3u">
                <a href="https://zollhoefer.com/" target="_blank"class="image">
                    <section>
                        
                        <img class="image-circle" src="/images/organisers/mz.png" alt="" style="  border-radius: 50%;"/>
                        <header>
                            <h3><strong>Michael<br> Zollhoefer</strong></h3>
                        </header>
                        <p>Facebook Reality Labs, USA</p>
                    </section>
                </a>
            </div>
        </div>

        <div class="row">

            <div class="3u">
                <a href="#" class="image">
                    <section>
                        <img class="image-circle" src="/images/organisers/dc.jpg" alt=""/>
                        <header>
                            <h3><strong>Dan<br> Casas</strong></h3>
                        </header>
                        <p>Multimodal Simulation Lab, Universidad Rey Juan Carlos, Spain</p>
                    </section>
                </a>

            </div>
            <div class="3u">
                <a href="#" class="image">
                    <section>
                        <img class="image-circle" src="/images/organisers/cr.jpg" alt=""/>
                        <header>
                            <h3><strong>Christian<br> Richardt</strong></h3>
                        </header>
                        <p>CAMERA, University of Bath, UK</p>
                    </section>
                </a>
            </div>
            <div class="3u">
                <a href="#" class="image">
                    <section>
                        <img class="image-circle" src="/images/organisers/ah.png" alt=""/>
                        <header>
                            <h3><strong>Adrian<br> Hilton</strong></h3>
                        </header>
                        <p>Centre for Vision, Speech and Signal Processing, University of Surrey, UK</p>
                    </section>
                </a>
            </div>
        </div>
    </section>
    
  
      <!-- Three -->
    <section class="wrapper style3 container special" id="program">
    
        <header class="major">
            <h2><strong>Sponsors</strong></h2>
        </header>
        <a href="https://www.nvidia.com/" target="_blank"><img class="image" src="/images/2020/nvidia.png" alt="" style="width:400px;"/> </a>
    </section>
  
  
</article>
